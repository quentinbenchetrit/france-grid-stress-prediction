{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f3cee3",
   "metadata": {},
   "source": [
    "# 03 — Feature Engineering\n",
    "\n",
    "Objectif : construire un jeu de données \"prêt modélisation\" à partir du dataset horaire final\n",
    "(consommation + météo), en créant des variables temporelles, retardées et dérivées,\n",
    "sans fuite d'information (time leakage), puis en définissant un split temporel\n",
    "(train/validation/test).\n",
    "\n",
    "**Entrée :** `data/processed/dataset_model_hourly.parquet`  \n",
    "**Sortie :** `data/processed/dataset_features.parquet` (ou splits séparés)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d78f135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/onyxia/france-grid-stress-prediction\")\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "IN_PATH = DATA_PROCESSED / \"dataset_model_hourly.parquet\"\n",
    "OUT_PATH = DATA_PROCESSED / \"dataset_features.parquet\"\n",
    "\n",
    "assert IN_PATH.exists(), f\"Missing input: {IN_PATH}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4782b331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>load_mw</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>cloud_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>52685.0</td>\n",
       "      <td>4.273719</td>\n",
       "      <td>12.397994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01 01:00:00</td>\n",
       "      <td>52142.5</td>\n",
       "      <td>4.036219</td>\n",
       "      <td>12.709288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.40625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01 02:00:00</td>\n",
       "      <td>52081.5</td>\n",
       "      <td>3.812781</td>\n",
       "      <td>13.122019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01 03:00:00</td>\n",
       "      <td>52331.5</td>\n",
       "      <td>3.598719</td>\n",
       "      <td>13.308270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01 04:00:00</td>\n",
       "      <td>52171.0</td>\n",
       "      <td>3.426844</td>\n",
       "      <td>14.081800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.78125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  load_mw  temperature_2m  wind_speed_10m  \\\n",
       "0 2010-01-01 00:00:00  52685.0        4.273719       12.397994   \n",
       "1 2010-01-01 01:00:00  52142.5        4.036219       12.709288   \n",
       "2 2010-01-01 02:00:00  52081.5        3.812781       13.122019   \n",
       "3 2010-01-01 03:00:00  52331.5        3.598719       13.308270   \n",
       "4 2010-01-01 04:00:00  52171.0        3.426844       14.081800   \n",
       "\n",
       "   direct_radiation  diffuse_radiation  cloud_cover  \n",
       "0               0.0                0.0     93.96875  \n",
       "1               0.0                0.0     95.40625  \n",
       "2               0.0                0.0     96.46875  \n",
       "3               0.0                0.0     96.87500  \n",
       "4               0.0                0.0     94.78125  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(IN_PATH)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2048890",
   "metadata": {},
   "source": [
    "## Verification de cohérence\n",
    "\n",
    "Vérifications minimales :\n",
    "- période couverte (min/max)\n",
    "- fréquence horaire (pas dominant)\n",
    "- valeurs manquantes par colonne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8814fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min datetime: 2010-01-01 00:00:00\n",
      "Max datetime: 2024-12-31 23:00:00\n",
      "N rows: 131496\n",
      "\n",
      "Top time diffs:\n",
      "datetime\n",
      "0 days 01:00:00    131495\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values (%):\n",
      "load_mw              3.92\n",
      "datetime             0.00\n",
      "temperature_2m       0.00\n",
      "wind_speed_10m       0.00\n",
      "direct_radiation     0.00\n",
      "diffuse_radiation    0.00\n",
      "cloud_cover          0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Min datetime:\", df[\"datetime\"].min())\n",
    "print(\"Max datetime:\", df[\"datetime\"].max())\n",
    "print(\"N rows:\", len(df))\n",
    "\n",
    "# fréquence dominante\n",
    "dt_diff = df[\"datetime\"].diff().value_counts().head(5)\n",
    "print(\"\\nTop time diffs:\")\n",
    "print(dt_diff)\n",
    "\n",
    "# NA par colonne\n",
    "na_pct = (df.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
    "print(\"\\nMissing values (%):\")\n",
    "print(na_pct.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df95c0",
   "metadata": {},
   "source": [
    "## Définition de la cible\n",
    "\n",
    "On commence avec une cible \"à l’heure\" : `y = load_mw`.\n",
    "Ensuite, on pourra créer une variante H+24 : `y_h24 = load_mw(t+24)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd6de15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"load_mw\"\n",
    "assert TARGET_COL in df.columns, f\"Missing target column: {TARGET_COL}\"\n",
    "\n",
    "df[\"y\"] = df[TARGET_COL].astype(float)\n",
    "\n",
    "# df[\"y_h24\"] = df[\"y\"].shift(-24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d839e",
   "metadata": {},
   "source": [
    "## Features calendaires\n",
    "\n",
    "But : capturer les effets \"humains\" (heures, jours ouvrés/week-end) et la saisonnalité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb1745f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"datetime\"].dt.weekday  # 0=Monday\n",
    "df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(int)\n",
    "df[\"month\"] = df[\"datetime\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"datetime\"].dt.dayofyear\n",
    "\n",
    "# Encodage cyclique (optionnel mais propre)\n",
    "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365.25)\n",
    "df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364bd39",
   "metadata": {},
   "source": [
    "## Lags\n",
    "\n",
    "But : donner au modèle l'inertie de la consommation (heure précédente, veille, semaine).\n",
    "Attention : cela crée des NA au début de la série (normal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3fcc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAGS_H = [1, 24, 48, 168]\n",
    "\n",
    "for lag in LAGS_H:\n",
    "    df[f\"load_lag_{lag}h\"] = df[\"y\"].shift(lag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc5106",
   "metadata": {},
   "source": [
    "## Rolling statistics\n",
    "\n",
    "But : fournir un contexte recent (niveau moyen, variabilité).\n",
    "Fenêtres typiques : 24h, 7j.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4299bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLL_WINDOWS = [24, 168]\n",
    "\n",
    "for w in ROLL_WINDOWS:\n",
    "    df[f\"load_roll_mean_{w}h\"] = df[\"y\"].shift(1).rolling(w).mean()\n",
    "    df[f\"load_roll_std_{w}h\"] = df[\"y\"].shift(1).rolling(w).std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3e201",
   "metadata": {},
   "source": [
    "## Features météo dérivées\n",
    "\n",
    "On calcule des degrés-jours chauffage (HDD) et climatisation (CDD) si une température existe.\n",
    "Adapte `TEMP_COL` selon le nom réel dans ton dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5620a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp candidates: ['temperature_2m']\n"
     ]
    }
   ],
   "source": [
    "# Adapte ce nom à ta colonne température réelle (ex: \"temperature\", \"temp\", \"t2m\", etc.)\n",
    "TEMP_COL_CANDIDATES = [c for c in df.columns if \"temp\" in c.lower()]\n",
    "print(\"Temp candidates:\", TEMP_COL_CANDIDATES[:10])\n",
    "\n",
    "# Exemple : tu fixes explicitement la colonne\n",
    "# TEMP_COL = \"temp\"\n",
    "TEMP_COL = None\n",
    "\n",
    "if TEMP_COL and TEMP_COL in df.columns:\n",
    "    df[\"hdd_18\"] = (18 - df[TEMP_COL]).clip(lower=0)\n",
    "    df[\"cdd_22\"] = (df[TEMP_COL] - 22).clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e909d",
   "metadata": {},
   "source": [
    "## Interactions (optionnel)\n",
    "\n",
    "Ajouter peu d’interactions (2–3 max) si elles sont justifiées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223e9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple si TEMP_COL existe\n",
    "# if TEMP_COL and TEMP_COL in df.columns:\n",
    "#     df[\"temp_x_weekend\"] = df[TEMP_COL] * df[\"is_weekend\"]\n",
    "#     df[\"temp_x_hour\"] = df[TEMP_COL] * df[\"hour\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cb4f2",
   "metadata": {},
   "source": [
    "## Gestion des valeurs manquantes\n",
    "\n",
    "On applique une règle simple : suppression des lignes contenant des NA dans les variables\n",
    "utilisées pour l'entraînement. On documente combien de lignes sont retirées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c045f69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 131496\n",
      "Rows after dropna: 125832\n",
      "Dropped: 5664\n"
     ]
    }
   ],
   "source": [
    "# Colonnes features (exclure datetime et target)\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in {\"datetime\", TARGET_COL, \"y\"} and not c.startswith(\"y_\")\n",
    "]\n",
    "\n",
    "before = len(df)\n",
    "df_feat = df.dropna(subset=feature_cols + [\"y\"]).copy()\n",
    "after = len(df_feat)\n",
    "\n",
    "print(\"Rows before:\", before)\n",
    "print(\"Rows after dropna:\", after)\n",
    "print(\"Dropped:\", before - after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13613a48",
   "metadata": {},
   "source": [
    "## Split temporel\n",
    "\n",
    "Découpage chronologique strict. Exemple :\n",
    "- train : 2010–2018\n",
    "- valid : 2019\n",
    "- test  : 2021–2022\n",
    "\n",
    "2020 peut être exclue (trou + période atypique) ou traitée à part.\n",
    "Adapte selon ta disponibilité réelle (min/max).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89ff7055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train     78720\n",
      "ignore    21000\n",
      "test      17352\n",
      "valid      8760\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_feat[\"year\"] = df_feat[\"datetime\"].dt.year\n",
    "\n",
    "def assign_split(y: int) -> str:\n",
    "    if 2010 <= y <= 2018:\n",
    "        return \"train\"\n",
    "    if y == 2019:\n",
    "        return \"valid\"\n",
    "    if 2021 <= y <= 2022:\n",
    "        return \"test\"\n",
    "    return \"ignore\"\n",
    "\n",
    "df_feat[\"split\"] = df_feat[\"year\"].apply(assign_split)\n",
    "\n",
    "print(df_feat[\"split\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413a028",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "On exporte un dataset unique avec une colonne `split`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a95af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/onyxia/france-grid-stress-prediction/data/processed/dataset_features.parquet\n",
      "               datetime        y  split  temperature_2m  wind_speed_10m  \\\n",
      "168 2010-01-08 00:00:00  74564.5  train       -2.365344       12.290582   \n",
      "169 2010-01-08 01:00:00  77065.5  train       -2.537219       12.808883   \n",
      "170 2010-01-08 02:00:00  82297.0  train       -2.552844       13.657961   \n",
      "171 2010-01-08 03:00:00  87563.0  train       -2.551281       14.603605   \n",
      "172 2010-01-08 04:00:00  89394.5  train       -2.530969       15.812960   \n",
      "\n",
      "     direct_radiation  diffuse_radiation  cloud_cover  hour  dayofweek  ...  \\\n",
      "168               0.0                0.0     67.06250     0          4  ...   \n",
      "169               0.0                0.0     70.78125     1          4  ...   \n",
      "170               0.0                0.0     73.93750     2          4  ...   \n",
      "171               0.0                0.0     77.56250     3          4  ...   \n",
      "172               0.0                0.0     80.96875     4          4  ...   \n",
      "\n",
      "      doy_sin   doy_cos  load_lag_1h  load_lag_24h  load_lag_48h  \\\n",
      "168  0.137185  0.990545      73921.5       73233.0       72064.5   \n",
      "169  0.137185  0.990545      74564.5       75735.5       74674.5   \n",
      "170  0.137185  0.990545      77065.5       80790.5       79808.5   \n",
      "171  0.137185  0.990545      82297.0       85729.0       84932.0   \n",
      "172  0.137185  0.990545      87563.0       86940.0       87177.5   \n",
      "\n",
      "     load_lag_168h  load_roll_mean_24h  load_roll_std_24h  \\\n",
      "168        52685.0        82903.416667        4661.838380   \n",
      "169        52142.5        82958.895833        4548.289956   \n",
      "170        52081.5        83014.312500        4463.770184   \n",
      "171        52331.5        83077.083333        4441.676382   \n",
      "172        52171.0        83153.500000        4504.615445   \n",
      "\n",
      "     load_roll_mean_168h  load_roll_std_168h  \n",
      "168         74125.791667        10498.593411  \n",
      "169         74256.026786        10365.896658  \n",
      "170         74404.377976        10224.908115  \n",
      "171         74584.232143        10094.816596  \n",
      "172         74793.943452         9995.227806  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [\"datetime\", \"y\", \"split\"] + feature_cols\n",
    "df_out = df_feat[keep_cols].copy()\n",
    "\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_parquet(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "print(df_out.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfa22d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ignore</th>\n",
       "      <td>21000</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>17352</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>78720</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>8760</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_rows      start                 end\n",
       "split                                        \n",
       "ignore   21000 2020-01-01 2024-12-31 23:00:00\n",
       "test     17352 2021-01-08 2022-12-31 23:00:00\n",
       "train    78720 2010-01-08 2018-12-31 23:00:00\n",
       "valid     8760 2019-01-01 2019-12-31 23:00:00"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = (\n",
    "    df_out.groupby(\"split\")\n",
    "    .agg(\n",
    "        n_rows=(\"y\", \"size\"),\n",
    "        start=(\"datetime\", \"min\"),\n",
    "        end=(\"datetime\", \"max\"),\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca325762",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Le dataset `dataset_features.parquet` contient :\n",
    "- la cible `y`\n",
    "- des variables calendaires + retardées + glissantes (+ météo dérivées si disponibles)\n",
    "- un split temporel strict (train/valid/test)\n",
    "\n",
    "La prochaine étape (`04_modeling.ipynb`) consiste à entraîner des modèles de référence\n",
    "(naïf, régression linéaire), puis des modèles ML (XGBoost/LightGBM), et comparer les performances.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
