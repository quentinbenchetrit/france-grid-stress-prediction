{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c016c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f564266",
   "metadata": {},
   "source": [
    "# 2. Nettoyage des données de consommation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c521e7a",
   "metadata": {},
   "source": [
    "## 2.1 Inspection initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14921173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17520 entries, 0 to 17519\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   datetime    17520 non-null  object\n",
      " 1   date        17520 non-null  object\n",
      " 2   year        17520 non-null  int64 \n",
      " 3   statut      17520 non-null  object\n",
      " 4   slot_index  17520 non-null  int64 \n",
      " 5   load_mw     17520 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 821.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>slot_index</th>\n",
       "      <th>load_mw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17520.0</td>\n",
       "      <td>17520.000000</td>\n",
       "      <td>17520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>53716.649030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.853794</td>\n",
       "      <td>11555.650027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>45030.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>52144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>61459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>88450.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          year    slot_index       load_mw\n",
       "count  17520.0  17520.000000  17520.000000\n",
       "mean    2019.0     23.500000  53716.649030\n",
       "std        0.0     13.853794  11555.650027\n",
       "min     2019.0      0.000000  30777.000000\n",
       "25%     2019.0     11.750000  45030.750000\n",
       "50%     2019.0     23.500000  52144.000000\n",
       "75%     2019.0     35.250000  61459.000000\n",
       "max     2019.0     47.000000  88450.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons = pd.read_csv(\"/home/onyxia/france-grid-stress-prediction/data/processed/consommation_2019_long.csv\")\n",
    "\n",
    "df_cons.head()\n",
    "df_cons.info()\n",
    "df_cons.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309b5b2",
   "metadata": {},
   "source": [
    "## 2.2 Nettoyage structurel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f104342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime      datetime64[ns]\n",
       "date                  object\n",
       "year                   int64\n",
       "statut                object\n",
       "slot_index             int64\n",
       "load_mw                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons[\"datetime\"] = pd.to_datetime(df_cons[\"datetime\"])\n",
    "df_cons.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589fb8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons[\"datetime\"].is_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb423b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "0 days 00:30:00    17519\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons = df_cons.sort_values(\"datetime\")\n",
    "delta = df_cons[\"datetime\"].diff()\n",
    "\n",
    "delta.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b436a612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaT\n",
       "Name: datetime, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta[delta != pd.Timedelta(\"30min\")].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db2a40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statut\n",
       "Provisoires    17520\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons[\"statut\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c2f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons = df_cons.drop(columns=[\"statut\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8138aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons[\"year\"] = df_cons[\"datetime\"].dt.year\n",
    "df_cons[\"date\"] = df_cons[\"datetime\"].dt.date\n",
    "df_cons[\"hour\"] = df_cons[\"datetime\"].dt.hour\n",
    "df_cons[\"minute\"] = df_cons[\"datetime\"].dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cee64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons = df_cons.drop(columns=[\"slot_index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb83fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17520 entries, 0 to 17519\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   datetime  17520 non-null  datetime64[ns]\n",
      " 1   date      17520 non-null  object        \n",
      " 2   year      17520 non-null  int32         \n",
      " 3   load_mw   17520 non-null  int64         \n",
      " 4   hour      17520 non-null  int32         \n",
      " 5   minute    17520 non-null  int32         \n",
      "dtypes: datetime64[ns](1), int32(3), int64(1), object(1)\n",
      "memory usage: 616.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>load_mw</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>53574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>52882</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>53140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 01:30:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>52870</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>53476</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        date  year  load_mw  hour  minute\n",
       "0 2019-01-01 00:00:00  2019-01-01  2019    53574     0       0\n",
       "1 2019-01-01 00:30:00  2019-01-01  2019    52882     0      30\n",
       "2 2019-01-01 01:00:00  2019-01-01  2019    53140     1       0\n",
       "3 2019-01-01 01:30:00  2019-01-01  2019    52870     1      30\n",
       "4 2019-01-01 02:00:00  2019-01-01  2019    53476     2       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cons.info()\n",
    "df_cons.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8cd37",
   "metadata": {},
   "source": [
    "## 2.3 Pipeline de nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae439b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_freq</th>\n",
       "      <th>top_deltas</th>\n",
       "      <th>n_non_expected_steps</th>\n",
       "      <th>file</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2010_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2011_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17567}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2012_long.csv</td>\n",
       "      <td>17568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2013_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2014_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2015_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17567}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2016_long.csv</td>\n",
       "      <td>17568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2017_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2018_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2019_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 7246, 154 days 00:30:00: 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>consommation_2020_long.csv</td>\n",
       "      <td>7248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2021_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2022_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17519}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2023_long.csv</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0 days 00:30:00</td>\n",
       "      <td>{0 days 00:30:00: 17567}</td>\n",
       "      <td>0</td>\n",
       "      <td>consommation_2024_long.csv</td>\n",
       "      <td>17568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      expected_freq                                     top_deltas  \\\n",
       "0   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "1   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "2   0 days 00:30:00                       {0 days 00:30:00: 17567}   \n",
       "3   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "4   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "5   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "6   0 days 00:30:00                       {0 days 00:30:00: 17567}   \n",
       "7   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "8   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "9   0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "10  0 days 00:30:00  {0 days 00:30:00: 7246, 154 days 00:30:00: 1}   \n",
       "11  0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "12  0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "13  0 days 00:30:00                       {0 days 00:30:00: 17519}   \n",
       "14  0 days 00:30:00                       {0 days 00:30:00: 17567}   \n",
       "\n",
       "    n_non_expected_steps                        file   rows  \n",
       "0                      0  consommation_2010_long.csv  17520  \n",
       "1                      0  consommation_2011_long.csv  17520  \n",
       "2                      0  consommation_2012_long.csv  17568  \n",
       "3                      0  consommation_2013_long.csv  17520  \n",
       "4                      0  consommation_2014_long.csv  17520  \n",
       "5                      0  consommation_2015_long.csv  17520  \n",
       "6                      0  consommation_2016_long.csv  17568  \n",
       "7                      0  consommation_2017_long.csv  17520  \n",
       "8                      0  consommation_2018_long.csv  17520  \n",
       "9                      0  consommation_2019_long.csv  17520  \n",
       "10                     1  consommation_2020_long.csv   7248  \n",
       "11                     0  consommation_2021_long.csv  17520  \n",
       "12                     0  consommation_2022_long.csv  17520  \n",
       "13                     0  consommation_2023_long.csv  17520  \n",
       "14                     0  consommation_2024_long.csv  17568  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path(\"/home/onyxia/france-grid-stress-prediction/data/processed\")\n",
    "OUT_PATH = DATA_DIR / \"consommation_clean.parquet\"\n",
    "\n",
    "\n",
    "EXPECTED_FREQ = pd.Timedelta(\"30min\")      # d'après ton fichier 2019 (48 slots/jour)\n",
    "\n",
    "def clean_consumption_file(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Nettoie un fichier consommation_YYYY_long.csv et renvoie un DataFrame standardisé.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # 1) Normaliser noms de colonnes\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # 2) Vérifier présence des colonnes minimales\n",
    "    required = {\"datetime\", \"load_mw\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name}: colonnes manquantes: {missing}\")\n",
    "\n",
    "    # 3) Convertir datetime\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    if df[\"datetime\"].isna().any():\n",
    "        bad = df[df[\"datetime\"].isna()].head(3)\n",
    "        raise ValueError(f\"{path.name}: datetimes invalides. Exemples:\\n{bad}\")\n",
    "\n",
    "    # 4) Trier + supprimer doublons exacts sur datetime\n",
    "    df = df.sort_values(\"datetime\")\n",
    "    df = df.drop_duplicates(subset=[\"datetime\"], keep=\"first\")\n",
    "\n",
    "    # 5) Sanity checks consommation\n",
    "    df[\"load_mw\"] = pd.to_numeric(df[\"load_mw\"], errors=\"coerce\")\n",
    "    df.loc[df[\"load_mw\"] < 0, \"load_mw\"] = np.nan\n",
    "\n",
    "    # 6) Statut: si constant -> drop, sinon garder\n",
    "    if \"statut\" in df.columns:\n",
    "        if df[\"statut\"].nunique(dropna=False) <= 1:\n",
    "            df = df.drop(columns=[\"statut\"])\n",
    "\n",
    "    # 7) Reconstruire variables temporelles propres\n",
    "    df[\"year\"] = df[\"datetime\"].dt.year\n",
    "    df[\"date\"] = df[\"datetime\"].dt.date\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"minute\"] = df[\"datetime\"].dt.minute\n",
    "\n",
    "    # 8) Slot index standardisé (0..47 si 30 min)\n",
    "    df[\"slot_index\"] = (df[\"hour\"] * 60 + df[\"minute\"]) // 30\n",
    "\n",
    "    # 9) Garder uniquement les colonnes finales (schéma stable)\n",
    "    df = df[[\"datetime\", \"year\", \"date\", \"hour\", \"minute\", \"slot_index\", \"load_mw\"]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def check_time_continuity(df: pd.DataFrame, freq: pd.Timedelta = EXPECTED_FREQ) -> dict:\n",
    "    \"\"\"Retourne un résumé de continuité temporelle (trous / pas atypiques).\"\"\"\n",
    "    d = df[\"datetime\"].sort_values().diff()\n",
    "    vc = d.value_counts().head(5)\n",
    "    n_bad = (d.notna() & (d != freq)).sum()\n",
    "    return {\n",
    "        \"expected_freq\": str(freq),\n",
    "        \"top_deltas\": vc.to_dict(),\n",
    "        \"n_non_expected_steps\": int(n_bad),\n",
    "    }\n",
    "\n",
    "\n",
    "# 1) Lister les fichiers consommation\n",
    "files = sorted(DATA_DIR.glob(\"consommation_*_long.csv\"))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Aucun fichier consommation trouvé dans {DATA_DIR}\")\n",
    "\n",
    "# 2) Nettoyer + concaténer\n",
    "cleaned = []\n",
    "reports = []\n",
    "\n",
    "for f in files:\n",
    "    df_f = clean_consumption_file(f)\n",
    "    rep = check_time_continuity(df_f)\n",
    "    rep[\"file\"] = f.name\n",
    "    rep[\"rows\"] = len(df_f)\n",
    "    reports.append(rep)\n",
    "    cleaned.append(df_f)\n",
    "\n",
    "df_cons_all = pd.concat(cleaned, ignore_index=True).sort_values(\"datetime\")\n",
    "\n",
    "# 3) Contrôles globaux\n",
    "df_cons_all = df_cons_all.drop_duplicates(subset=[\"datetime\"], keep=\"first\")\n",
    "\n",
    "# 4) Sauvegarde\n",
    "df_cons_all.to_parquet(OUT_PATH, index=False)\n",
    "\n",
    "reports_df = pd.DataFrame(reports).sort_values(\"file\")\n",
    "reports_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276ac27",
   "metadata": {},
   "source": [
    "# 3. Nettoyage des données météo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54270cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(\n",
    "    \"/home/onyxia/france-grid-stress-prediction/weather_32_cities_2019.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e0f02",
   "metadata": {},
   "source": [
    "## 3.1 Inspection initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad9a920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280320 entries, 0 to 280319\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   date               280320 non-null  object \n",
      " 1   temperature_2m     280320 non-null  float64\n",
      " 2   wind_speed_10m     280320 non-null  float64\n",
      " 3   direct_radiation   280320 non-null  float64\n",
      " 4   diffuse_radiation  280320 non-null  float64\n",
      " 5   cloud_cover        280320 non-null  float64\n",
      " 6   city               280320 non-null  object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 15.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>280320</td>\n",
       "      <td>280320.000000</td>\n",
       "      <td>280320.000000</td>\n",
       "      <td>280320.000000</td>\n",
       "      <td>280320.000000</td>\n",
       "      <td>280320.000000</td>\n",
       "      <td>280320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2019-01-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.052136</td>\n",
       "      <td>12.807939</td>\n",
       "      <td>99.881503</td>\n",
       "      <td>54.635745</td>\n",
       "      <td>56.794467</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.380206</td>\n",
       "      <td>7.717712</td>\n",
       "      <td>179.211120</td>\n",
       "      <td>75.575675</td>\n",
       "      <td>40.239133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.304501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.613000</td>\n",
       "      <td>7.091177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.461251</td>\n",
       "      <td>11.159999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.915500</td>\n",
       "      <td>16.946787</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.494003</td>\n",
       "      <td>60.720590</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  temperature_2m  wind_speed_10m  \\\n",
       "count                      280320   280320.000000   280320.000000   \n",
       "unique                       8760             NaN             NaN   \n",
       "top     2019-01-01 00:00:00+00:00             NaN             NaN   \n",
       "freq                           32             NaN             NaN   \n",
       "mean                          NaN       13.052136       12.807939   \n",
       "std                           NaN        7.380206        7.717712   \n",
       "min                           NaN       -9.304501        0.000000   \n",
       "25%                           NaN        7.613000        7.091177   \n",
       "50%                           NaN       12.461251       11.159999   \n",
       "75%                           NaN       17.915500       16.946787   \n",
       "max                           NaN       41.494003       60.720590   \n",
       "\n",
       "        direct_radiation  diffuse_radiation    cloud_cover    city  \n",
       "count      280320.000000      280320.000000  280320.000000  280320  \n",
       "unique               NaN                NaN            NaN      32  \n",
       "top                  NaN                NaN            NaN   Paris  \n",
       "freq                 NaN                NaN            NaN    8760  \n",
       "mean           99.881503          54.635745      56.794467     NaN  \n",
       "std           179.211120          75.575675      40.239133     NaN  \n",
       "min             0.000000           0.000000       0.000000     NaN  \n",
       "25%             0.000000           0.000000      12.000000     NaN  \n",
       "50%             0.000000           5.000000      66.000000     NaN  \n",
       "75%           120.000000          96.000000      98.000000     NaN  \n",
       "max           843.000000         448.000000     100.000000     NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()\n",
    "df_weather.info()\n",
    "df_weather.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98c343ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Paris', 'Lyon', 'Marseille - Aix-en-Provence', 'Toulouse',\n",
       "       'Bordeaux', 'Lille (partie française)', 'Nice', 'Nantes',\n",
       "       'Strasbourg (partie française)', 'Rennes', 'Grenoble', 'Rouen',\n",
       "       'Toulon', 'Montpellier', 'Douai - Lens', 'Avignon',\n",
       "       'Saint-Étienne', 'Tours', 'Clermont-Ferrand', 'Orléans', 'Nancy',\n",
       "       'Angers', 'Caen', 'Metz', 'Dijon',\n",
       "       'Valenciennes (partie française)', 'Béthune', 'Le Mans',\n",
       "       'Genève - Annemasse (partie française)', 'Perpignan', 'Reims',\n",
       "       'Brest'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather[\"city\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3027d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[\"datetime\"] = pd.to_datetime(df_weather[\"date\"], utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c2e0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[\"datetime\"] = df_weather[\"datetime\"].dt.tz_convert(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "141f4029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather.drop(columns=[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fe74182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather.sort_values([\"city\", \"datetime\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604f848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 280320 entries, 183960 to 227759\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   temperature_2m     280320 non-null  float64       \n",
      " 1   wind_speed_10m     280320 non-null  float64       \n",
      " 2   direct_radiation   280320 non-null  float64       \n",
      " 3   diffuse_radiation  280320 non-null  float64       \n",
      " 4   cloud_cover        280320 non-null  float64       \n",
      " 5   city               280320 non-null  object        \n",
      " 6   datetime           280320 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 17.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>city</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183960</th>\n",
       "      <td>7.3305</td>\n",
       "      <td>4.379589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Angers</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183961</th>\n",
       "      <td>7.4805</td>\n",
       "      <td>3.259939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Angers</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183962</th>\n",
       "      <td>7.3805</td>\n",
       "      <td>4.104631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Angers</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183963</th>\n",
       "      <td>7.6305</td>\n",
       "      <td>6.618519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Angers</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183964</th>\n",
       "      <td>7.3305</td>\n",
       "      <td>6.989936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Angers</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_2m  wind_speed_10m  direct_radiation  diffuse_radiation  \\\n",
       "183960          7.3305        4.379589               0.0                0.0   \n",
       "183961          7.4805        3.259939               0.0                0.0   \n",
       "183962          7.3805        4.104631               0.0                0.0   \n",
       "183963          7.6305        6.618519               0.0                0.0   \n",
       "183964          7.3305        6.989936               0.0                0.0   \n",
       "\n",
       "        cloud_cover    city            datetime  \n",
       "183960         99.0  Angers 2019-01-01 00:00:00  \n",
       "183961        100.0  Angers 2019-01-01 01:00:00  \n",
       "183962        100.0  Angers 2019-01-01 02:00:00  \n",
       "183963         99.0  Angers 2019-01-01 03:00:00  \n",
       "183964         90.0  Angers 2019-01-01 04:00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.info()\n",
    "df_weather.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1905e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Angers',\n",
       "  'Avignon',\n",
       "  'Bordeaux',\n",
       "  'Brest',\n",
       "  'Béthune',\n",
       "  'Caen',\n",
       "  'Clermont-Ferrand',\n",
       "  'Dijon',\n",
       "  'Douai - Lens',\n",
       "  'Genève - Annemasse (partie française)',\n",
       "  'Grenoble',\n",
       "  'Le Mans',\n",
       "  'Lille (partie française)',\n",
       "  'Lyon',\n",
       "  'Marseille - Aix-en-Provence',\n",
       "  'Metz',\n",
       "  'Montpellier',\n",
       "  'Nancy',\n",
       "  'Nantes',\n",
       "  'Nice',\n",
       "  'Orléans',\n",
       "  'Paris',\n",
       "  'Perpignan',\n",
       "  'Reims',\n",
       "  'Rennes',\n",
       "  'Rouen',\n",
       "  'Saint-Étienne',\n",
       "  'Strasbourg (partie française)',\n",
       "  'Toulon',\n",
       "  'Toulouse',\n",
       "  'Tours',\n",
       "  'Valenciennes (partie française)'],\n",
       " 32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = sorted(df_weather[\"city\"].unique())\n",
    "cities, len(cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99dbb07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "0 days 01:00:00    8759\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_test = \"Paris\"  \n",
    "df_city = df_weather[df_weather[\"city\"] == city_test].sort_values(\"datetime\")\n",
    "\n",
    "delta = df_city[\"datetime\"].diff()\n",
    "delta.value_counts().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b224ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20509/4107833812.py:1: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  delta[delta != pd.Timedelta(\"1H\")].head()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   NaT\n",
       "Name: datetime, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta[delta != pd.Timedelta(\"1H\")].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7c8d4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      32.0\n",
       "mean     8760.0\n",
       "std         0.0\n",
       "min      8760.0\n",
       "25%      8760.0\n",
       "50%      8760.0\n",
       "75%      8760.0\n",
       "max      8760.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather[\"city\"].value_counts().describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336b762",
   "metadata": {},
   "source": [
    "## 3.2 Pipeline de Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91b2bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20509/3951242131.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  EXPECTED_FREQ = pd.Timedelta(\"1H\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_bad_steps</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angers</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avignon</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brest</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Béthune</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Strasbourg (partie française)</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_historical_2014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Toulon</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_historical_2014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Toulouse</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_historical_2014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Tours</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_historical_2014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Valenciennes (partie française)</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>weather_32_cities_historical_2014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                city  n_obs  n_bad_steps  \\\n",
       "0                             Angers   8760            0   \n",
       "1                            Avignon   8760            0   \n",
       "2                           Bordeaux   8760            0   \n",
       "3                              Brest   8760            0   \n",
       "4                            Béthune   8760            0   \n",
       "..                               ...    ...          ...   \n",
       "475    Strasbourg (partie française)   8760            0   \n",
       "476                           Toulon   8760            0   \n",
       "477                         Toulouse   8760            0   \n",
       "478                            Tours   8760            0   \n",
       "479  Valenciennes (partie française)   8760            0   \n",
       "\n",
       "                                      file  \n",
       "0               weather_32_cities_2015.csv  \n",
       "1               weather_32_cities_2015.csv  \n",
       "2               weather_32_cities_2015.csv  \n",
       "3               weather_32_cities_2015.csv  \n",
       "4               weather_32_cities_2015.csv  \n",
       "..                                     ...  \n",
       "475  weather_32_cities_historical_2014.csv  \n",
       "476  weather_32_cities_historical_2014.csv  \n",
       "477  weather_32_cities_historical_2014.csv  \n",
       "478  weather_32_cities_historical_2014.csv  \n",
       "479  weather_32_cities_historical_2014.csv  \n",
       "\n",
       "[480 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path(\"/home/onyxia/france-grid-stress-prediction/data/raw*/weather/\")\n",
    "OUT_PATH_WEATHER = DATA_DIR / \"weather_national_hourly.parquet\"\n",
    "EXPECTED_FREQ = pd.Timedelta(\"1H\")\n",
    "\n",
    "def clean_weather_file(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Nettoie un fichier météo multi-villes et retourne un DataFrame propre.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Normaliser noms de colonnes\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # Conversion datetime (UTC → naive)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"date\"], utc=True).dt.tz_convert(None)\n",
    "    df = df.drop(columns=[\"date\"])\n",
    "\n",
    "    # Tri obligatoire\n",
    "    df = df.sort_values([\"city\", \"datetime\"])\n",
    "\n",
    "    # Sanity checks physiques\n",
    "    df.loc[df[\"temperature_2m\"] < -50, \"temperature_2m\"] = np.nan\n",
    "    df.loc[df[\"temperature_2m\"] > 60, \"temperature_2m\"] = np.nan\n",
    "\n",
    "    df.loc[df[\"cloud_cover\"] < 0, \"cloud_cover\"] = np.nan\n",
    "    df.loc[df[\"cloud_cover\"] > 100, \"cloud_cover\"] = np.nan\n",
    "\n",
    "    # Pas de valeurs négatives physiques\n",
    "    for col in [\"wind_speed_10m\", \"direct_radiation\", \"diffuse_radiation\"]:\n",
    "        df.loc[df[col] < 0, col] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_weather_continuity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Vérifie la continuité horaire pour chaque ville.\n",
    "    \"\"\"\n",
    "    reports = []\n",
    "\n",
    "    for city, g in df.groupby(\"city\"):\n",
    "        delta = g.sort_values(\"datetime\")[\"datetime\"].diff()\n",
    "        bad_steps = (delta.notna() & (delta != EXPECTED_FREQ)).sum()\n",
    "\n",
    "        reports.append({\n",
    "            \"city\": city,\n",
    "            \"n_obs\": len(g),\n",
    "            \"n_bad_steps\": int(bad_steps)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(reports)\n",
    "\n",
    "def aggregate_weather_national(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrège la météo multi-villes en indicateurs nationaux horaires.\n",
    "    \"\"\"\n",
    "    weather_nat = (\n",
    "        df.groupby(\"datetime\")\n",
    "          .agg({\n",
    "              \"temperature_2m\": \"mean\",\n",
    "              \"wind_speed_10m\": \"mean\",\n",
    "              \"direct_radiation\": \"mean\",\n",
    "              \"diffuse_radiation\": \"mean\",\n",
    "              \"cloud_cover\": \"mean\"\n",
    "          })\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    return weather_nat\n",
    "\n",
    "files = sorted(DATA_DIR.glob(\"weather_32_cities_*.csv\"))\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"Aucun fichier météo trouvé\")\n",
    "\n",
    "cleaned_weather = []\n",
    "continuity_reports = []\n",
    "\n",
    "for f in files:\n",
    "    df_w = clean_weather_file(f)\n",
    "\n",
    "    # Audit qualité par ville\n",
    "    rep = check_weather_continuity(df_w)\n",
    "    rep[\"file\"] = f.name\n",
    "    continuity_reports.append(rep)\n",
    "\n",
    "    cleaned_weather.append(df_w)\n",
    "\n",
    "# Concaténation multi-années\n",
    "df_weather_all = pd.concat(cleaned_weather, ignore_index=True)\n",
    "\n",
    "# Agrégation nationale\n",
    "df_weather_national = aggregate_weather_national(df_weather_all)\n",
    "\n",
    "# Sauvegarde\n",
    "OUT_PATH_WEATHER.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_weather_national.to_parquet(OUT_PATH_WEATHER, index=False)\n",
    "\n",
    "# Rapport qualité\n",
    "weather_quality = pd.concat(continuity_reports, ignore_index=True)\n",
    "weather_quality\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
