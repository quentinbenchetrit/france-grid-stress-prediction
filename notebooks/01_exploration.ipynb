{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7fc246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00+00:00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>26.874910</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00+00:00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>25.570139</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 02:00:00+00:00</td>\n",
       "      <td>7.16</td>\n",
       "      <td>25.704100</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 03:00:00+00:00</td>\n",
       "      <td>6.96</td>\n",
       "      <td>25.199997</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 04:00:00+00:00</td>\n",
       "      <td>6.81</td>\n",
       "      <td>24.774696</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  temperature_2m  wind_speed_10m  cloud_cover  \\\n",
       "0  2024-01-01 00:00:00+00:00            7.31       26.874910         35.0   \n",
       "1  2024-01-01 01:00:00+00:00            7.31       25.570139         51.0   \n",
       "2  2024-01-01 02:00:00+00:00            7.16       25.704100         24.0   \n",
       "3  2024-01-01 03:00:00+00:00            6.96       25.199997         40.0   \n",
       "4  2024-01-01 04:00:00+00:00            6.81       24.774696         47.0   \n",
       "\n",
       "   direct_radiation  diffuse_radiation  \n",
       "0               0.0                0.0  \n",
       "1               0.0                0.0  \n",
       "2               0.0                0.0  \n",
       "3               0.0                0.0  \n",
       "4               0.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather=pd.read_csv('/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_paris_2024.csv')\n",
    "\n",
    "weather.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e746041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   date               8784 non-null   object \n",
      " 1   temperature_2m     8784 non-null   float64\n",
      " 2   wind_speed_10m     8784 non-null   float64\n",
      " 3   cloud_cover        8784 non-null   float64\n",
      " 4   direct_radiation   8784 non-null   float64\n",
      " 5   diffuse_radiation  8784 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 411.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2024-01-01 00:00:00+00:00', '2024-12-31 23:00:00+00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.info()\n",
    "weather.describe()\n",
    "weather.isna().sum()\n",
    "weather['date'].min(), weather['date'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d77bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00+00:00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>26.874910</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00+00:00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>25.570139</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 02:00:00+00:00</td>\n",
       "      <td>7.16</td>\n",
       "      <td>25.704100</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 03:00:00+00:00</td>\n",
       "      <td>6.96</td>\n",
       "      <td>25.199997</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 04:00:00+00:00</td>\n",
       "      <td>6.81</td>\n",
       "      <td>24.774696</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  temperature_2m  wind_speed_10m  cloud_cover  \\\n",
       "0  2024-01-01 00:00:00+00:00            7.31       26.874910         35.0   \n",
       "1  2024-01-01 01:00:00+00:00            7.31       25.570139         51.0   \n",
       "2  2024-01-01 02:00:00+00:00            7.16       25.704100         24.0   \n",
       "3  2024-01-01 03:00:00+00:00            6.96       25.199997         40.0   \n",
       "4  2024-01-01 04:00:00+00:00            6.81       24.774696         47.0   \n",
       "\n",
       "   direct_radiation  diffuse_radiation  \n",
       "0               0.0                0.0  \n",
       "1               0.0                0.0  \n",
       "2               0.0                0.0  \n",
       "3               0.0                0.0  \n",
       "4               0.0                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d560f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/onyxia/france-grid-stress-prediction/data/raw/consommation/Historique_consommation_INST_2016.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m zip_path = Path(\n\u001b[32m      8\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/home/onyxia/france-grid-stress-prediction/data/raw/consommation/Historique_consommation_INST_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[32m2016\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. Lecture du zip -> CSV -> DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m z:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# liste des fichiers contenus dans le zip\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mContenu du zip :\u001b[39m\u001b[33m\"\u001b[39m, z.namelist())\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# on prend le premier fichier (en général le bon)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/zipfile/__init__.py:1367\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1369\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/onyxia/france-grid-stress-prediction/data/raw/consommation/Historique_consommation_INST_2016.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Chemin vers TON fichier zip (adapter l'année ici)\n",
    "year = 2016\n",
    "zip_path = Path(\n",
    "    f\"/home/onyxia/france-grid-stress-prediction/data/raw/consommation/Historique_consommation_INST_{2016}.zip\"\n",
    ")\n",
    "\n",
    "# 2. Lecture du zip -> CSV -> DataFrame\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    # liste des fichiers contenus dans le zip\n",
    "    print(\"Contenu du zip :\", z.namelist())\n",
    "\n",
    "    # on prend le premier fichier (en général le bon)\n",
    "    inner_name = z.namelist()[0]\n",
    "\n",
    "    # lecture du CSV (séparateur ; pour les fichiers RTE)\n",
    "    df = pd.read_csv(z.open(inner_name), sep=\";\", engine=\"python\")\n",
    "\n",
    "# 3. Aperçu\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d977175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/france-grid-stress-prediction/data/raw*\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/README.md\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2022.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_1997.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2019.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2000.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2011.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2001.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2014.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2020.xls\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2010.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2018.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_1996.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2024.xls\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2009.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2003.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2004.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2012.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2006.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2017.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2025.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_1998.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2020.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2005.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2008.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2016.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2021.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2023.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2013.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_1999.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2007.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2002.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2015.zip\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2014.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2015.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2023.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2024.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2016.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2013.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_paris_2024.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2022.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2019.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2012.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2021.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2018.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2011.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2017.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2010.csv\n",
      "/home/onyxia/france-grid-stress-prediction/data/raw*/weather/weather_idf_departements_2020.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base = Path(\"/home/onyxia/france-grid-stress-prediction/data\")\n",
    "for p in base.rglob(\"*\"):\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d216c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du zip : ['Historique_consommation_INST_2016.xls']\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd0 in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mContenu du zip :\u001b[39m\u001b[33m\"\u001b[39m, z.namelist())\n\u001b[32m      8\u001b[39m     inner = z.namelist()[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/python_parser.py:133\u001b[39m, in \u001b[36mPythonParser.__init__\u001b[39m\u001b[34m(self, f, **kwds)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m._col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    128\u001b[39m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar | \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[32m    129\u001b[39m (\n\u001b[32m    130\u001b[39m     columns,\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_original_columns,\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m.unnamed_cols,\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[32m    138\u001b[39m (\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.columns,\n\u001b[32m    140\u001b[39m     \u001b[38;5;28mself\u001b[39m.index_names,\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m.index_names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    146\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/python_parser.py:404\u001b[39m, in \u001b[36mPythonParser._infer_columns\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m level, hr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(header):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m         line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffered_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.line_pos <= hr:\n\u001b[32m    407\u001b[39m             line = \u001b[38;5;28mself\u001b[39m._next_line()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/python_parser.py:637\u001b[39m, in \u001b[36mPythonParser._buffered_line\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.buf[\u001b[32m0\u001b[39m]\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/python_parser.py:738\u001b[39m, in \u001b[36mPythonParser._next_line\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     orig_line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    739\u001b[39m     \u001b[38;5;28mself\u001b[39m.pos += \u001b[32m1\u001b[39m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m orig_line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parsers/python_parser.py:805\u001b[39m, in \u001b[36mPythonParser._next_iter_line\u001b[39m\u001b[34m(self, row_num)\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    803\u001b[39m     \u001b[38;5;66;03m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[32m    804\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     line = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    806\u001b[39m     \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(line, \u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xd0 in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_path = \"/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2016.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    print(\"Contenu du zip :\", z.namelist())\n",
    "    inner = z.namelist()[0]\n",
    "    df = pd.read_csv(z.open(inner), sep=\";\", engine=\"python\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2df693b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf08e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du zip : ['Historique_consommation_INST_2016.xls']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 40 Unnamed: 41  \\\n",
       "0        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
       "1        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
       "2        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
       "3        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
       "4        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
       "\n",
       "  Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45 Unnamed: 46 Unnamed: 47  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 48 Unnamed: 49  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_path = \"/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2016.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    print(\"Contenu du zip :\", z.namelist())\n",
    "    inner = z.namelist()[0]  # Historique_consommation_INST_2016.xls\n",
    "    \n",
    "    # Lecture du fichier Excel directement depuis le zip\n",
    "    with z.open(inner) as f:\n",
    "        df = pd.read_excel(f)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ef0f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 50)\n",
      "  Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 40 Unnamed: 41  \\\n",
      "0        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
      "1        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
      "2        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
      "3        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
      "4        NaN        NaN        NaN        NaN  ...         NaN         NaN   \n",
      "\n",
      "  Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45 Unnamed: 46 Unnamed: 47  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 48 Unnamed: 49  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "     Unnamed: 0   Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
      "391  27/12/2016  Définitives      60481      58009      57727      57255   \n",
      "392  28/12/2016  Définitives      65492      63013      62800      62408   \n",
      "393  29/12/2016  Définitives      68276      65720      65544      65169   \n",
      "394  30/12/2016  Définitives      70861      68286      67830      67204   \n",
      "395  31/12/2016  Définitives      72715      70283      69981      69389   \n",
      "\n",
      "    Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 40 Unnamed: 41  \\\n",
      "391      57019      55235      54469      53676  ...       71213       70054   \n",
      "392      62105      60323      59267      58397  ...       73795       72550   \n",
      "393      64997      63147      62162      61255  ...       77462       76078   \n",
      "394      66736      65016      63806      62879  ...       79214       77812   \n",
      "395      68734      66735      65493      64402  ...       77188       75653   \n",
      "\n",
      "    Unnamed: 42 Unnamed: 43 Unnamed: 44 Unnamed: 45 Unnamed: 46 Unnamed: 47  \\\n",
      "391       68428       66903       65638       64641       65057       67953   \n",
      "392       70742       68990       68036       66745       67296       70327   \n",
      "393       74067       72336       70959       69706       70110       73160   \n",
      "394       76047       74294       72974       71818       72112       75112   \n",
      "395       73831       72375       71318       70793       71924       75424   \n",
      "\n",
      "    Unnamed: 48 Unnamed: 49  \n",
      "391       67243       67250  \n",
      "392       69704       69900  \n",
      "393       72442       72396  \n",
      "394       74255       74259  \n",
      "395       75504       76259  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_path = \"/home/onyxia/france-grid-stress-prediction/data/raw*/consommation/Historique_consommation_INST_2016.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    inner = z.namelist()[0]   # 'Historique_consommation_INST_2016.xls'\n",
    "    with z.open(inner) as f:\n",
    "        df_raw = pd.read_excel(f)   # pas de header spécial\n",
    "\n",
    "print(df_raw.shape)\n",
    "print(df_raw.head())\n",
    "print(df_raw.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd732ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366, 51)\n",
      "         date       statut\n",
      "19 2016-01-01  Définitives\n",
      "20 2016-01-02  Définitives\n",
      "21 2016-01-03  Définitives\n",
      "22 2016-01-04  Définitives\n",
      "23 2016-01-05  Définitives\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# 1) On renomme pour que ce soit plus clair\n",
    "df.columns = [f\"col_{i}\" for i in range(df.shape[1])]\n",
    "\n",
    "# 2) On garde les lignes où col_0 est une vraie date (format jour/mois/année)\n",
    "dates = pd.to_datetime(df[\"col_0\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df = df[dates.notna()].copy()\n",
    "df[\"date\"] = dates\n",
    "\n",
    "# 3) On renomme les deux premières colonnes utiles\n",
    "df = df.rename(columns={\n",
    "    \"col_0\": \"date_str\",\n",
    "    \"col_1\": \"statut\"\n",
    "})\n",
    "\n",
    "# 4) On enlève les colonnes entièrement vides (si besoin)\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df[[\"date\", \"statut\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "975e2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime       date       statut  slot_index load_mw\n",
      "0 2016-01-01 00:00:00 2016-01-01  Définitives           0   49345\n",
      "1 2016-01-01 00:30:00 2016-01-01  Définitives           1   48657\n",
      "2 2016-01-01 01:00:00 2016-01-01  Définitives           2   48865\n",
      "3 2016-01-01 01:30:00 2016-01-01  Définitives           3   48743\n",
      "4 2016-01-01 02:00:00 2016-01-01  Définitives           4   49216\n",
      "                 datetime       date       statut  slot_index load_mw\n",
      "17563 2016-12-31 21:30:00 2016-12-31  Définitives          43   69389\n",
      "17564 2016-12-31 22:00:00 2016-12-31  Définitives          44   68734\n",
      "17565 2016-12-31 22:30:00 2016-12-31  Définitives          45   66735\n",
      "17566 2016-12-31 23:00:00 2016-12-31  Définitives          46   65493\n",
      "17567 2016-12-31 23:30:00 2016-12-31  Définitives          47   64402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Colonnes de pas de temps = toutes sauf 'date', 'date_str', 'statut'\n",
    "time_cols = [c for c in df.columns if c not in [\"date\", \"date_str\", \"statut\"]]\n",
    "\n",
    "# On passe en long : une ligne = (date, slot_index, valeur)\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"date\", \"statut\"],\n",
    "    value_vars=time_cols,\n",
    "    var_name=\"slot_col\",\n",
    "    value_name=\"load_mw\"\n",
    ")\n",
    "\n",
    "# On ordonne par date + colonne\n",
    "df_long = df_long.sort_values([\"date\", \"slot_col\"]).reset_index(drop=True)\n",
    "\n",
    "# Index de pas de temps par jour : 0,1,2,... pour chaque date\n",
    "df_long[\"slot_index\"] = df_long.groupby(\"date\").cumcount()\n",
    "\n",
    "# Hypothèse : chaque slot = 30 minutes (à adapter si c'est 1h)\n",
    "df_long[\"datetime\"] = df_long[\"date\"] + pd.to_timedelta(df_long[\"slot_index\"] * 30, unit=\"m\")\n",
    "\n",
    "# On garde l’essentiel\n",
    "df_long = df_long[[\"datetime\", \"date\", \"statut\", \"slot_index\", \"load_mw\"]]\n",
    "\n",
    "print(df_long.head())\n",
    "print(df_long.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9da19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé dans : /home/onyxia/france-grid-stress-prediction/data/processed/consommation_2016_long.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Créer le dossier processed s'il n'existe pas\n",
    "processed_dir = Path(\"/home/onyxia/france-grid-stress-prediction/data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sauvegarde\n",
    "output_file = processed_dir / \"consommation_2016_long.csv\"\n",
    "df_long.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Fichier sauvegardé dans :\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
